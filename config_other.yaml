seed: 42
device: "mps"  # cpu or cuda
overwrite: False
save: False

input:
  training_path: datasets/reviews_train.csv
  test_path: datasets/reviews_test.csv
  path: datasets
  batch_size: 100
  dataset: "mnist" # "mnist" or "fmnist" or "cifar10" or "cifar100" or "senti"
  number_samples: 10000 # Number of samples to use for training and testing for quicker runs.


model:
  dropout: True # Set to true to use dropout.
  softmax: True # Set to true to use softmax.
  maxsubtract: False # Set to true to use maxsubtract.

  peer_normalization: 0.03
  momentum: 0.9  # Momentum to use for the running mean in peer normalization loss.
  droprate: 0.1 # Dropout rate.
  parbp_steps: 2

  threshold: 1  # Threshold for loss computation.
  structure: "CwC" # "FF" or "BP" or "BP/FF" or "ParBP" or "CwC" or "AE" or "VAE" or "VFFAE" or "FFCVAE"

  hidden_dim: 2000
  num_layers: 4


training:
  epochs: 10

  optimizer: "Adam"  # "Adam" or "SGD"
  learning_rate: 1e-3
  weight_decay: 3e-4
  momentum: 0.9
  betas: [0.9, 0.999]

  downstream_learning_rate: 1e-2
  downstream_weight_decay: 3e-3

  val_idx: -1  # -1: validate only once training has finished; n: validate every n epochs.
  final_test: True  # Set to true to evaluate performance on test-set.


hydra:
  run:
    dir: logs

CwC:
  channel_list: [20, 80, 240, 480] #  [20, 80, 240, 480] for the rest [60, 120, 240, 400, 800, 1600] for CIFAR-100
  CFSE: False # True = CFSE or False = FFCNN
  sf_pred: True # True = Avg+Sf, False = Avg
  loss: "CwC" # "CwC" or "CwC_CE" or "PvN" or "CWG"
  ILT: "Acc" # "Acc" or "Fast"
  N_Classes: [20, 20, 20, 20, 100, 100] # Empty or [] list for class groups split args.N_Classes = [20, 20, 20, 20, 100, 100] only for CIFAR-100

AE:
  channel_list: [20, 40, 80, 40] # [20, 40, 80, 40] for MNIST
  enc_kernel: [{"kernel_size": 5, "stride": 2, "padding": 2}, {"kernel_size": 5, "stride": 2, "padding": 2}, {"kernel_size": 3, "stride": 2, "padding": 1}, {"kernel_size": 4, "stride": 1, "padding": 0}]
  dec_kernel: [{"kernel_size": 4, "stride": 1, "padding": 0}, {"kernel_size": 5, "stride": 2, "padding": 2}, {"kernel_size": 4, "stride": 2, "padding": 1}, {"kernel_size": 4, "stride": 2, "padding": 1}]
  CFSE: False # True = CFSE or False = FFCNN
  sf_pred: True # True = Avg+Sf, False = Avg
  loss: "CwC" # "CwC" or "CwC_CE" or "PvN" or "CWG"
  N_Classes: [20, 20, 20, 20, 100, 100] # Empty or [] list for class groups split args.N_Classes = [20, 20, 20, 20, 100, 100] only for CIFAR-100

VAE:
  enc_channel_list: [60, 120] # [20, 40, 80, 40] for MNIST
  dec_channel_list: [60, 1] # [20, 40, 80, 40] for MNIST
  latent_dim: 40 # 128
  latent_shape: [24,34] # latent_shape: [7,9] 
  batchnorm_enc: [False, True]
  batchnorm_dec: [True, False]
  relu_enc: ["leakyrelu", "leakyrelu"]
  relu_dec: ["leakyrelu", "sigmoid"]
  enc_kernel: [{"kernel_size": 3, "stride": 1, "padding": 0}, {"kernel_size": 3, "stride": 1, "padding": 0}] # enc_kernel: [{"kernel_size": 4, "stride": 2, "padding": 1}, {"kernel_size": 4, "stride": 2, "padding": 1}]
  dec_kernel: [{"kernel_size": 3, "stride": 1, "padding": 0, "output_padding": 0}, {"kernel_size": 3, "stride": 1, "padding": 0, "output_padding": 0}] # dec_kernel: [{"kernel_size": 4, "stride": 2, "padding": 1, "output_padding": 0}, {"kernel_size": 4, "stride": 2, "padding": 1, "output_padding": 0}]
  CFSE: False # True = CFSE or False = FFCNN
  sf_pred: True # True = Avg+Sf, False = Avg
  loss: "CwC" # "CwC" or "CwC_CE" or "PvN" or "CWG"
  beta: 0.5
  max_capacity: 25
  N_Classes: [20, 20, 20, 20, 100, 100] # Empty or [] list for class groups split args.N_Classes = [20, 20, 20, 20, 100, 100] only for CIFAR-100
  latent_FF: True # True = FF, False = BP
  mirror: True

  # https://github.com/o-tawab/Variational-Autoencoder-pytorch/blob/master/graph/mse_model.py CIFAR10 COMPLEX
  # enc_channel_list: [60, 120, 240, 360] # [20, 40, 80, 40] for MNIST
  # dec_channel_list: [240, 120, 60, 1] # [20, 40, 80, 40] for MNIST
  # latent_dim: 10 # 128
  # latent_shape: 8 #2 
  # enc_kernel: [{"kernel_size": 3, "stride": 1, "padding": 1}, {"kernel_size": 3, "stride": 2, "padding": 1}, {"kernel_size": 3, "stride": 1, "padding": 1}, {"kernel_size": 3, "stride": 2, "padding": 1}]
  # dec_kernel: [{"kernel_size": 3, "stride": 2, "padding": 1, "output_padding": 1}, {"kernel_size": 3, "stride": 1, "padding": 1, "output_padding": 0}, {"kernel_size": 3, "stride": 2, "padding": 1, "output_padding": 1}, {"kernel_size": 3, "stride": 1, "padding": 1, "output_padding": 0}]

  # https://github.com/SashaMalysheva/Pytorch-VAE/blob/master/train.py#L42 CIFAR10 BASIC
  # latent_dim: 2 # 128
  # latent_shape: 4 #2 
  # enc_kernel: [{"kernel_size": 4, "stride": 2, "padding": 1}, {"kernel_size": 4, "stride": 2, "padding": 1}, {"kernel_size": 4, "stride": 2, "padding": 1}]
  # dec_kernel: [{"kernel_size": 4, "stride": 2, "padding": 1, "output_padding": 0}, {"kernel_size": 4, "stride": 2, "padding": 1, "output_padding": 0}, {"kernel_size": 4, "stride": 2, "padding": 1, "output_padding": 0}]

VFFAE:
  classifier: False # True = train a classifier, False = do not train a classifier

VAE_BOH:
  in_channels: 3
  latent_dim: 128
  loss_type: 'B'
  gamma: 10.0
  max_capacity: 25
  Capacity_max_iter: 10000
  hidden_dims: [32, 64, 128, 256, 512] #list or None

  # exp params
  LR: 0.005
  weight_decay: 0.0
  scheduler_gamma: 0.95
  kld_weight: 0.00025
  manual_seed: 1265